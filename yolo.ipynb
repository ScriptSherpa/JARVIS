{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb67XCVjUkNhEYiib9FRpp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ScriptSherpa/JARVIS/blob/master/yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "2cy9LwkqAK2Q",
        "outputId": "4d683b7e-4adc-48dc-f835-935785ffeb73"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.layers.merge'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d2d6352e55c4>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.merge'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model"
      ]
    },
    {
      "source": [
        "from keras.layers import add, concatenate"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-8wTyH1IA5q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "import struct\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import add, concatenate # updated import\n",
        "from keras.models import Model\n",
        "# %%\n",
        "def _conv_block(inp, convs, skip=True):\n",
        "\tx = inp\n",
        "\tcount = 0\n",
        "\tfor conv in convs:\n",
        "\t\tif count == (len(convs) - 2) and skip:\n",
        "\t\t\tskip_connection = x\n",
        "\t\tcount += 1\n",
        "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) #padding as darknet prefer left and top\n",
        "\t\tx = Conv2D(conv['filter'],\n",
        "\t\t\t\t   conv['kernel'],\n",
        "\t\t\t\t   strides=conv['stride'],\n",
        "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', #  padding as darknet prefer left and top\n",
        "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
        "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
        "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\treturn add([skip_connection, x]) if skip else x"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "woQgbJqgA6wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "\tx = inp\n",
        "\tcount = 0\n",
        "\tfor conv in convs:\n",
        "\t\tif count == (len(convs) - 2) and skip:\n",
        "\t\t\tskip_connection = x\n",
        "\t\tcount += 1\n",
        "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) #padding as darknet prefer left and top\n",
        "\t\tx = Conv2D(conv['filter'],\n",
        "\t\t\t\t   conv['kernel'],\n",
        "\t\t\t\t   strides=conv['stride'],\n",
        "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', #  padding as darknet prefer left and top\n",
        "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
        "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
        "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\treturn add([skip_connection, x]) if skip else x"
      ],
      "metadata": {
        "id": "onMMRXBHAiPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yolov3_model():\n",
        "\tinput_image = Input(shape=(None, None, 3))\n",
        "\t# Layer  0 => 4\n",
        "\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\t# Layer  5 => 8\n",
        "\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\t# Layer  9 => 11\n",
        "\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\t# Layer 12 => 15\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\t# Layer 16 => 36\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\tskip_36 = x\n",
        "\t# Layer 37 => 40\n",
        "\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\t# Layer 41 => 61\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\tskip_61 = x\n",
        "\t# Layer 62 => 65\n",
        "\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\t# Layer 66 => 74\n",
        "\tfor i in range(3):\n",
        "\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\t# Layer 75 => 79\n",
        "\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\t# Layer 80 => 82\n",
        "\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\t# Layer 83 => 86\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_61])\n",
        "\t# Layer 87 => 91\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\t# Layer 92 => 94\n",
        "\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\t# Layer 95 => 98\n",
        "\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_36])\n",
        "\t# Layer 99 => 106\n",
        "\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "2xZadStmBGne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightReader:\n",
        "\tdef __init__(self, weight_file):\n",
        "\t\twith open(weight_file, 'rb') as w_f:\n",
        "\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n",
        "\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n",
        "\t\t\trevision, = struct.unpack('i', w_f.read(4))\n",
        "\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "\t\t\t\tw_f.read(8)\n",
        "\t\t\telse:\n",
        "\t\t\t\tw_f.read(4)\n",
        "\t\t\ttranspose = (major > 1000) or (minor > 1000)\n",
        "\t\t\tbinary = w_f.read()\n",
        "\t\tself.offset = 0\n",
        "\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "\n",
        "\tdef read_bytes(self, size):\n",
        "\t\tself.offset = self.offset + size\n",
        "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "\tdef load_weights(self, model):\n",
        "\t\tfor i in range(106):\n",
        "\t\t\ttry:\n",
        "\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n",
        "\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n",
        "\t\t\t\tif i not in [81, 93, 105]:\n",
        "\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n",
        "\t\t\t\t\tgamma = self.read_bytes(size) # scale\n",
        "\t\t\t\t\tmean  = self.read_bytes(size) # mean\n",
        "\t\t\t\t\tvar   = self.read_bytes(size) # variance\n",
        "\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "\t\t\t\tif len(conv_layer.get_weights()) > 1:\n",
        "\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
        "\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
        "\t\t\t\t\tconv_layer.set_weights([kernel])\n",
        "\t\t\texcept ValueError:\n",
        "\t\t\t\tprint(\"no convolution #\" + str(i))\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.offset = 0"
      ],
      "metadata": {
        "id": "EkNzaG3KBSkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define the model\n",
        "model = make_yolov3_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rci7tXMCBVZd",
        "outputId": "f2296402-f791-4a3b-dc5e-0926c1fac42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_reader = WeightReader('yolov3.weights')\n"
      ],
      "metadata": {
        "id": "32SfKftvBa-V",
        "outputId": "92060e54-2cc2-4a59-9755-eacc41154def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'yolov3.weights'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b286e1331fa0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweight_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeightReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov3.weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-88db993dcd0b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mWeightReader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                         \u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov3.weights'"
          ]
        }
      ]
    }
  ]
}